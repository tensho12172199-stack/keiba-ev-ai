import pandas as pd
import numpy as np
import lightgbm as lgb
import joblib
from pathlib import Path
import gc
import glob
import warnings
from datetime import datetime
from typing import List, Tuple, Optional

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from feature_engineering import apply_all_features
from add_passing_features import add_passing_features
from add_jockey_style_features import add_jockey_style_features
from add_speed_features import add_speed_features
from add_distance_preference_features import add_distance_preference_features
from add_recent_diff_features import add_recent_diff_features

warnings.filterwarnings('ignore')

# =====================
# è¨­å®šã‚¯ãƒ©ã‚¹
# =====================
class Config:
    """å­¦ç¿’ã®è¨­å®šã‚’ä¸€å…ƒç®¡ç†"""
    
    # ãƒ‘ã‚¹è¨­å®š
    DATA_DIR = Path("data")
    OUT_DIR = Path("outputs")
    MODEL_FILE = OUT_DIR / "horse_racing_lgbm_ranker.txt"
    FEATURE_LIST_FILE = OUT_DIR / "feature_list.pkl"
    IMPORTANCE_FILE = OUT_DIR / "feature_importance.csv"
    METRICS_FILE = OUT_DIR / "training_metrics.csv"
    
    # ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ©ãƒ 
    HORSE_KEY = "horse_name"
    DATE_KEY = "race_date"
    TARGET = "rank"
    RACE_ID = "race_id"
    
    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    LGBM_PARAMS = {
        "objective": "lambdarank",
        "metric": "ndcg",
        "ndcg_eval_at": [1, 3, 5],
        "num_leaves": 31,
        "learning_rate": 0.05,
        "n_estimators": 800,
        "min_child_samples": 20,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "random_state": 42,
        "importance_type": "gain",
        "verbose": -1
    }
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆæ—¥ä»˜ãƒ™ãƒ¼ã‚¹ï¼‰
    TRAIN_END_DATE = "2024-06-30"  # ã“ã®æ—¥ä»˜ã¾ã§ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿
    
    # é™¤å¤–ã‚«ãƒ©ãƒ 
    IGNORE_COLS = [
        "race_id", "race_name", "date", DATE_KEY,
        "horse_name", "horse_id", "jockey", "trainer", "owner",
        TARGET,
        # ãƒªãƒ¼ã‚¯ï¼ˆçµæœï¼‰ç³»
        "time", "time_sec", "time_per_meter", "time_diff_race",
        "passing", "passing_1c", "passing_4c", "passing_gain",
        "age_sex", "horse_weight", "horse_weight_diff",
        # äººæ°—ç³»ï¼ˆé‡è¦åº¦ã‚’ä¸‹ã’ã‚‹ãŸã‚é™¤å¤–ï¼‰
        "popularity", "log_popularity", "odds",
        "popularity_recent_avg_3", "popularity_recent_diff_3",
    ]


# =====================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =====================
def setup_directories() -> None:
    """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ"""
    Config.OUT_DIR.mkdir(exist_ok=True, parents=True)
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {Config.OUT_DIR}")


def load_csv_files() -> pd.DataFrame:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
    print("\n" + "="*60)
    print("ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    
    csv_files = sorted(Config.DATA_DIR.glob("*.csv"))
    
    if not csv_files:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚æ¢ã™
        csv_files = sorted(glob.glob("*.csv"))
        if not csv_files:
            raise FileNotFoundError(
                f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
                f"   {Config.DATA_DIR} ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )
    
    print(f"   è¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(csv_files)}å€‹")
    for f in csv_files:
        print(f"   - {f.name}")
    
    dfs = []
    for f in csv_files:
        try:
            df = pd.read_csv(f)
            dfs.append(df)
        except Exception as e:
            print(f"âš ï¸  {f.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
    
    if not dfs:
        raise ValueError("æœ‰åŠ¹ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
    
    df = pd.concat(dfs, ignore_index=True)
    print(f"âœ… èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,} è¡Œ")
    
    return df


def preprocess_basic(df: pd.DataFrame) -> pd.DataFrame:
    """åŸºæœ¬çš„ãªå‰å‡¦ç†"""
    print("\n" + "="*60)
    print("ğŸ”§ åŸºæœ¬å‰å‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
    
    initial_rows = len(df)
    
    # é †ä½ã®æ•°å€¤åŒ–ã¨æ¬ æé™¤å»
    df[Config.TARGET] = pd.to_numeric(df[Config.TARGET], errors="coerce")
    df = df.dropna(subset=[Config.TARGET])
    df[Config.TARGET] = df[Config.TARGET].astype(int)
    
    removed_rows = initial_rows - len(df)
    if removed_rows > 0:
        print(f"   ç„¡åŠ¹ãªé †ä½ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»: {removed_rows:,} è¡Œ")
    
    # æ—¥ä»˜å‹å¤‰æ›
    if Config.DATE_KEY in df.columns:
        df[Config.DATE_KEY] = pd.to_datetime(df[Config.DATE_KEY], errors="coerce")
        date_nulls = df[Config.DATE_KEY].isna().sum()
        if date_nulls > 0:
            print(f"   âš ï¸  æ—¥ä»˜ãŒç„¡åŠ¹: {date_nulls:,} è¡Œ")
    
    # å…±é€šã®å‰å‡¦ç†
    df = apply_all_features(df)
    
    print(f"âœ… åŸºæœ¬å‰å‡¦ç†å®Œäº†: {len(df):,} è¡Œ")
    
    return df


def generate_features(df: pd.DataFrame) -> pd.DataFrame:
    """é«˜åº¦ãªç‰¹å¾´é‡ç”Ÿæˆ"""
    print("\n" + "="*60)
    print("ğŸ¯ ç‰¹å¾´é‡ç”Ÿæˆã‚’å®Ÿè¡Œä¸­...")
    
    # horse_id ãŒãªã„å ´åˆã¯ç”Ÿæˆ
    if "horse_id" not in df.columns and Config.HORSE_KEY in df.columns:
        print(f"   horse_id ã‚’ {Config.HORSE_KEY} ã‹ã‚‰ç”Ÿæˆ")
        df["horse_id"] = pd.factorize(df[Config.HORSE_KEY])[0]
    
    # ã‚½ãƒ¼ãƒˆ
    if Config.DATE_KEY in df.columns:
        df = df.sort_values([Config.DATE_KEY, Config.RACE_ID])
    
    # å„ç‰¹å¾´é‡ã®è¿½åŠ ï¼ˆå¿…é ˆã‚«ãƒ©ãƒ ã®å®šç¾©ã‚’æ‹¡å¼µï¼‰
    feature_funcs = [
        ("é€šéé †ç‰¹å¾´é‡", add_passing_features, ["passing"]),
        ("é¨æ‰‹å‚¾å‘ç‰¹å¾´é‡", lambda x: add_jockey_style_features(x, "jockey_profile.csv"), []),
        ("ã‚¹ãƒ”ãƒ¼ãƒ‰ç‰¹å¾´é‡", add_speed_features, ["distance", "time_sec"]),
        ("è·é›¢é©æ€§ç‰¹å¾´é‡", add_distance_preference_features, ["distance", "speed"]),
        ("è¿‘èµ°å·®åˆ†ç‰¹å¾´é‡", lambda x: add_recent_diff_features(x, n_recent=3), []),
    ]
    
    for name, func, required_cols in feature_funcs:
        try:
            # å¿…é ˆã‚«ãƒ©ãƒ ã®ãƒã‚§ãƒƒã‚¯
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                print(f"   âš ï¸  {name}: å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³ {missing_cols} - ã‚¹ã‚­ãƒƒãƒ—")
                continue
            
            print(f"   âœ“ {name} ã‚’è¿½åŠ ä¸­...")
            df = func(df)
        except Exception as e:
            print(f"   âš ï¸  {name} ã®ç”Ÿæˆã«å¤±æ•—: {e}")
            import traceback
            print(f"      è©³ç´°: {traceback.format_exc()[:200]}")
    
    print(f"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†")
    
    return df


def prepare_dataset(df: pd.DataFrame) -> Tuple[List[str], pd.DataFrame, pd.DataFrame]:
    """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™"""
    print("\n" + "="*60)
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ä¸­...")
    
    # æ•°å€¤å‹ã®ã¿æŠ½å‡º
    numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns.tolist()
    
    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã®ç¢ºå®š
    features = [c for c in numeric_cols if c not in Config.IGNORE_COLS]
    
    print(f"   ç‰¹å¾´é‡æ•°: {len(features)}")
    print(f"   é™¤å¤–ã‚«ãƒ©ãƒ æ•°: {len(Config.IGNORE_COLS)}")
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆæ—¥ä»˜ãƒ™ãƒ¼ã‚¹ï¼‰
    if Config.DATE_KEY in df.columns:
        train_end = pd.to_datetime(Config.TRAIN_END_DATE)
        train_df = df[df[Config.DATE_KEY] <= train_end].copy()
        valid_df = df[df[Config.DATE_KEY] > train_end].copy()
        
        print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_df):,} è¡Œ (ï½{Config.TRAIN_END_DATE})")
        print(f"   æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(valid_df):,} è¡Œ ({Config.TRAIN_END_DATE}ï½)")
    else:
        # æ—¥ä»˜ãŒãªã„å ´åˆã¯8:2ã§åˆ†å‰²
        print("   âš ï¸  æ—¥ä»˜ã‚«ãƒ©ãƒ ãŒãªã„ãŸã‚ã€ãƒ©ãƒ³ãƒ€ãƒ ã«8:2åˆ†å‰²")
        train_df = df.sample(frac=0.8, random_state=42)
        valid_df = df.drop(train_df.index)
        
        print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_df):,} è¡Œ")
        print(f"   æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(valid_df):,} è¡Œ")
    
    # ãƒ¬ãƒ¼ã‚¹IDã§ã‚½ãƒ¼ãƒˆ
    train_df = train_df.sort_values(Config.RACE_ID)
    valid_df = valid_df.sort_values(Config.RACE_ID)
    
    return features, train_df, valid_df


def create_ranker_dataset(
    df: pd.DataFrame,
    features: List[str]
) -> Tuple[pd.DataFrame, np.ndarray, np.ndarray]:
    """LightGBM Rankerç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ"""
    X = df[features]
    y = df[Config.TARGET]
    group = df.groupby(Config.RACE_ID).size().to_numpy()
    
    return X, y, group


def train_model(
    train_data: Tuple[pd.DataFrame, np.ndarray, np.ndarray],
    valid_data: Tuple[pd.DataFrame, np.ndarray, np.ndarray],
    features: List[str]
) -> lgb.LGBMRanker:
    """ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
    print("\n" + "="*60)
    print("ğŸš€ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’é–‹å§‹...")
    
    X_train, y_train, group_train = train_data
    X_valid, y_valid, group_valid = valid_data
    
    print(f"   è¨“ç·´ãƒ¬ãƒ¼ã‚¹æ•°: {len(group_train):,}")
    print(f"   æ¤œè¨¼ãƒ¬ãƒ¼ã‚¹æ•°: {len(group_valid):,}")
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    model = lgb.LGBMRanker(**Config.LGBM_PARAMS)
    
    # å­¦ç¿’
    start_time = datetime.now()
    
    model.fit(
        X_train, y_train,
        group=group_train,
        eval_set=[(X_valid, y_valid)],
        eval_group=[group_valid],
        eval_metric="ndcg",
        callbacks=[
            lgb.log_evaluation(period=100),
            lgb.early_stopping(stopping_rounds=50, verbose=True)
        ]
    )
    
    elapsed = (datetime.now() - start_time).total_seconds()
    print(f"\nâœ… å­¦ç¿’å®Œäº† (æ‰€è¦æ™‚é–“: {elapsed:.1f}ç§’)")
    
    return model


def evaluate_model(
    model: lgb.LGBMRanker,
    valid_data: Tuple[pd.DataFrame, np.ndarray, np.ndarray],
    features: List[str]
) -> pd.DataFrame:
    """ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡"""
    print("\n" + "="*60)
    print("ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...")
    
    X_valid, y_valid, group_valid = valid_data
    
    # äºˆæ¸¬
    y_pred = model.predict(X_valid)
    
    # ãƒ¬ãƒ¼ã‚¹å˜ä½ã§ã®è©•ä¾¡
    metrics = []
    start_idx = 0
    
    for group_size in group_valid:
        end_idx = start_idx + group_size
        
        race_true = y_valid.iloc[start_idx:end_idx].values
        race_pred = y_pred[start_idx:end_idx]
        
        # NDCG@3ã®è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        top3_pred_idx = np.argsort(race_pred)[:3]
        top3_true = race_true[top3_pred_idx]
        
        # ä¸Šä½3ç€ã«å…¥ã£ã¦ã„ã‚‹ã‹ã‚«ã‚¦ãƒ³ãƒˆ
        hit_top3 = np.sum(top3_true <= 3)
        
        metrics.append({
            "race_size": group_size,
            "hit_top3": hit_top3
        })
        
        start_idx = end_idx
    
    metrics_df = pd.DataFrame(metrics)
    
    # çµ±è¨ˆè¡¨ç¤º
    accuracy_top3 = (metrics_df["hit_top3"] > 0).mean()
    avg_hit = metrics_df["hit_top3"].mean()
    
    print(f"   æ¤œè¨¼ãƒ¬ãƒ¼ã‚¹æ•°: {len(metrics_df):,}")
    print(f"   Top3çš„ä¸­ç‡: {accuracy_top3:.2%}")
    print(f"   å¹³å‡çš„ä¸­é ­æ•°: {avg_hit:.2f}")
    
    return metrics_df


def save_artifacts(
    model: lgb.LGBMRanker,
    features: List[str],
    metrics: pd.DataFrame
) -> None:
    """ãƒ¢ãƒ‡ãƒ«ã¨é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜"""
    print("\n" + "="*60)
    print("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã¨çµæœã‚’ä¿å­˜ä¸­...")
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model.booster_.save_model(str(Config.MODEL_FILE))
    print(f"   âœ“ ãƒ¢ãƒ‡ãƒ«: {Config.MODEL_FILE}")
    
    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆä¿å­˜
    joblib.dump(features, Config.FEATURE_LIST_FILE)
    print(f"   âœ“ ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ: {Config.FEATURE_LIST_FILE}")
    
    # ç‰¹å¾´é‡é‡è¦åº¦
    importance_df = pd.DataFrame({
        "feature": features,
        "importance": model.feature_importances_
    }).sort_values("importance", ascending=False)
    
    importance_df.to_csv(Config.IMPORTANCE_FILE, index=False)
    print(f"   âœ“ ç‰¹å¾´é‡é‡è¦åº¦: {Config.IMPORTANCE_FILE}")
    
    # è©•ä¾¡æŒ‡æ¨™
    metrics.to_csv(Config.METRICS_FILE, index=False)
    print(f"   âœ“ è©•ä¾¡æŒ‡æ¨™: {Config.METRICS_FILE}")
    
    # é‡è¦åº¦Top20è¡¨ç¤º
    print("\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ (Top 20)")
    print("-" * 60)
    for idx, row in importance_df.head(20).iterrows():
        print(f"   {row['feature']:40s} {row['importance']:>10.1f}")


# =====================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =====================
def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("\n" + "="*60)
    print("ğŸ‡ ç«¶é¦¬äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("="*60)
    
    try:
        # 1. æº–å‚™
        setup_directories()
        
        # 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = load_csv_files()
        
        # 3. å‰å‡¦ç†
        df = preprocess_basic(df)
        
        # 4. ç‰¹å¾´é‡ç”Ÿæˆ
        df = generate_features(df)
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        gc.collect()
        
        # 5. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
        features, train_df, valid_df = prepare_dataset(df)
        
        # 6. Rankerç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        train_data = create_ranker_dataset(train_df, features)
        valid_data = create_ranker_dataset(valid_df, features)
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del df, train_df, valid_df
        gc.collect()
        
        # 7. å­¦ç¿’
        model = train_model(train_data, valid_data, features)
        
        # 8. è©•ä¾¡
        metrics = evaluate_model(model, valid_data, features)
        
        # 9. ä¿å­˜
        save_artifacts(model, features, metrics)
        
        print("\n" + "="*60)
        print("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("="*60)
        
    except Exception as e:
        print("\n" + "="*60)
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("="*60)
        raise


if __name__ == "__main__":
    main()
