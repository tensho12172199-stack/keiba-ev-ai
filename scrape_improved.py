"""
ç«¶é¦¬ãƒ¬ãƒ¼ã‚¹çµæœã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹å–„ç‰ˆï¼‰

æ©Ÿèƒ½:
- æœ€æ–°ã®çµæœãŒå‡ºã¦ã„ã‚‹ãƒ¬ãƒ¼ã‚¹ã¾ã§è‡ªå‹•å–å¾—
- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ¸ˆã¿ã®ãƒ¬ãƒ¼ã‚¹ã¯è‡ªå‹•ã‚¹ã‚­ãƒƒãƒ—
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
- é€²æ—çŠ¶æ³ã®è©³ç´°è¡¨ç¤º
- ä¿®æ­£: å…¨ãƒ¬ãƒ¼ã‚¹ã‚’ç¢ºå®Ÿã«å–å¾—ã§ãã‚‹ã‚ˆã†ãƒ«ãƒ¼ãƒ—æ§‹é€ ã‚’æ”¹å–„
"""

import requests
from bs4 import BeautifulSoup
import time
import os
import psycopg2
from datetime import datetime, timedelta
import re
from typing import List, Tuple, Optional, Set

# =========================
# DBè¨­å®š
# =========================
DB_URL = os.environ.get("DB_URL") or os.environ.get("DATABASE_URL")

if not DB_URL:
    raise ValueError("ç’°å¢ƒå¤‰æ•° DB_URL ã¾ãŸã¯ DATABASE_URL ã‚’è¨­å®šã—ã¦ãã ã•ã„")

def get_conn():
    """DBæ¥ç¶šã‚’å–å¾—"""
    return psycopg2.connect(
        DB_URL,
        sslmode="require",
        connect_timeout=10
    )

# =========================
# å–å¾—æ¸ˆã¿race_idã‚’ç®¡ç†
# =========================
def load_done_ids() -> Set[str]:
    """å–å¾—æ¸ˆã¿ã®ãƒ¬ãƒ¼ã‚¹IDã‚’DBã‹ã‚‰èª­ã¿è¾¼ã¿"""
    try:
        conn = get_conn()
        cur = conn.cursor()
        cur.execute("SELECT DISTINCT race_id FROM race_results")
        ids = set(r[0] for r in cur.fetchall())
        cur.close()
        conn.close()
        print(f"âœ“ å–å¾—æ¸ˆã¿ãƒ¬ãƒ¼ã‚¹æ•°: {len(ids)}")
        return ids
    except Exception as e:
        print(f"âš ï¸  å–å¾—æ¸ˆã¿IDèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return set()

# =========================
# å–å¾—æœŸé–“ã®è¨­å®š
# =========================
def get_date_range() -> Tuple[int, int]:
    """
    å–å¾—ã™ã‚‹å¹´ã®ç¯„å›²ã‚’æ±ºå®š
    
    Returns:
        (é–‹å§‹å¹´, çµ‚äº†å¹´)
    """
    current_year = datetime.now().year
    current_month = datetime.now().month
    
    # ä»Šå¹´ã®ãƒ¬ãƒ¼ã‚¹ãŒå§‹ã¾ã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    # 1æœˆãªã‚‰å‰å¹´æœ«ã¾ã§ã€ãã‚Œä»¥é™ãªã‚‰ä»Šå¹´ã‚‚å«ã‚€
    if current_month == 1:
        end_year = current_year - 1
    else:
        end_year = current_year
    
    # éå»5å¹´åˆ†ã‚’å–å¾—
    start_year = end_year - 4
    
    return start_year, end_year

# =========================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =========================
def safe(tag) -> Optional[str]:
    """ã‚¿ã‚°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«å–å¾—"""
    return tag.text.strip() if tag else None

def time_to_sec(t: str) -> Optional[float]:
    """ã‚¿ã‚¤ãƒ æ–‡å­—åˆ—ã‚’ç§’æ•°ã«å¤‰æ›"""
    if not t or ":" not in t:
        return None
    try:
        parts = t.split(":")
        if len(parts) == 2:
            m, s = parts
            return int(m) * 60 + float(s)
    except:
        pass
    return None

def parse_weight(w: str) -> Optional[int]:
    """é¦¬ä½“é‡æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹"""
    if not w or "(" not in w:
        return None
    try:
        return int(w.split("(")[0])
    except:
        return None

def parse_date(text: str) -> Optional[str]:
    """æ—¥ä»˜æ–‡å­—åˆ—ã‚’YYYY-MM-DDå½¢å¼ã«å¤‰æ›"""
    if not text:
        return None
    # 2024å¹´12æœˆ25æ—¥ å½¢å¼
    m = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', text)
    if m:
        return f"{m.group(1)}-{m.group(2).zfill(2)}-{m.group(3).zfill(2)}"
    return None

# =========================
# ãƒ¬ãƒ¼ã‚¹çµæœã‚’å–å¾—
# =========================
def scrape_race(race_id: str) -> Optional[List[Tuple]]:
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¬ãƒ¼ã‚¹IDã®çµæœã‚’å–å¾—
    
    Args:
        race_id: ãƒ¬ãƒ¼ã‚¹ID (ä¾‹: "202406030811")
    
    Returns:
        ãƒ¬ãƒ¼ã‚¹çµæœã®ãƒªã‚¹ãƒˆã€ã¾ãŸã¯ Noneï¼ˆãƒ¬ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    """
    url = f"https://db.netkeiba.com/race/{race_id}"
    
    try:
        r = requests.get(
            url, 
            headers={"User-Agent": "Mozilla/5.0"}, 
            timeout=15
        )
        r.encoding = "EUC-JP"
        
        if r.status_code != 200:
            return None
        
        soup = BeautifulSoup(r.text, "html.parser")
        
        # çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
        table = soup.find("table", class_="race_table_01")
        if not table:
            # å‡ºèµ°è¡¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚‚ç¢ºèªï¼ˆãƒ¬ãƒ¼ã‚¹ãŒæœªå®Ÿæ–½ã®å¯èƒ½æ€§ï¼‰
            shutuba_table = soup.find("table", class_="Shutuba_Table")
            if shutuba_table:
                # å‡ºèµ°è¡¨ãŒã‚ã‚‹ = ãƒ¬ãƒ¼ã‚¹æœªå®Ÿæ–½
                return None
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå…¨ããªã„ = ãƒ¬ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ãªã„
            return None
        
        # ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—
        race_name = safe(soup.find("h1"))
        info = safe(soup.find("div", class_="data_intro")) or ""
        
        # è·é›¢
        dist_match = re.search(r'(\d+)m', info)
        distance = int(dist_match.group(1)) if dist_match else None
        
        # ã‚³ãƒ¼ã‚¹ç¨®åˆ¥
        course_type = "èŠ" if "èŠ" in info else "ãƒ€ãƒ¼ãƒˆ"
        
        # ãƒˆãƒ©ãƒƒã‚¯æ–¹å‘
        track_direction = "å³" if "å³" in info else "å·¦"
        
        # å¤©å€™
        weather = safe(soup.find("span", class_="weather"))
        
        # é¦¬å ´çŠ¶æ…‹
        track_condition = safe(soup.find("span", class_="condition"))
        
        # ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜
        raw_date = safe(soup.find("p", class_="smalltxt"))
        race_date = parse_date(raw_date)
        
        results = []
        
        # å„é¦¬ã®çµæœã‚’å–å¾—
        for row in table.find_all("tr")[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            c = row.find_all("td")
            if len(c) < 18:
                continue
            
            # ç€é †
            rank_text = c[0].text.strip()
            rank = int(rank_text) if rank_text.isdigit() else None
            
            # ã‚ªãƒƒã‚º
            odds_text = c[12].text.strip()
            odds = float(odds_text) if odds_text not in ["", "---", "----"] else None
            
            # äººæ°—
            pop_text = c[13].text.strip()
            popularity = int(pop_text) if pop_text.isdigit() else None
            
            # ã‚¿ã‚¤ãƒ 
            time_sec = time_to_sec(c[7].text.strip())
            
            # é¦¬ä½“é‡
            weight = parse_weight(c[14].text.strip())
            
            # ä¸ŠãŒã‚Š3F
            last_3f_text = c[11].text.strip()
            last_3f = float(last_3f_text) if last_3f_text not in ["", "---"] else None
            
            results.append((
                race_id,           # race_id
                race_name,         # race_name
                rank,              # rank
                int(c[1].text.strip()),  # horse_no (æ ç•ª)
                int(c[2].text.strip()),  # horse_no (é¦¬ç•ª)
                c[3].text.strip(),       # horse_name
                c[4].text.strip(),       # sex_age
                float(c[5].text.strip()), # weight_carrier
                c[6].text.strip(),       # jockey
                time_sec,                # time_sec
                c[8].text.strip(),       # margin
                c[10].text.strip(),      # passing
                last_3f,                 # last_3f
                odds,                    # odds
                popularity,              # popularity
                weight,                  # horse_weight
                info,                    # race_info
                race_date,               # race_date
                distance,                # distance
                course_type,             # course_type
                track_direction,         # track_direction
                weather,                 # weather
                track_condition          # track_condition
            ))
        
        return results if results else None
    
    except requests.RequestException as e:
        print(f"âš ï¸  {race_id}: é€šä¿¡ã‚¨ãƒ©ãƒ¼ - {e}")
        return None
    except Exception as e:
        print(f"âš ï¸  {race_id}: ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ - {e}")
        return None

# =========================
# DBä¿å­˜
# =========================
def save_to_db(rows: List[Tuple]) -> bool:
    """
    ãƒ¬ãƒ¼ã‚¹çµæœã‚’DBã«ä¿å­˜
    
    Args:
        rows: ãƒ¬ãƒ¼ã‚¹çµæœã®ãƒªã‚¹ãƒˆ
    
    Returns:
        æˆåŠŸã—ãŸã‚‰True
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        cur.executemany("""
            INSERT INTO race_results (
                race_id, race_name, rank, waku_no, horse_no,
                horse_name, sex_age, weight_carrier, jockey, time_sec,
                margin, passing, last_3f, odds, popularity,
                horse_weight, race_info, race_date, distance,
                course_type, track_direction, weather, track_condition
            ) VALUES (
                %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,
                %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,
                %s,%s,%s
            )
            ON CONFLICT (race_id, horse_no)
            DO UPDATE SET
                rank=EXCLUDED.rank,
                odds=EXCLUDED.odds,
                time_sec=EXCLUDED.time_sec,
                popularity=EXCLUDED.popularity
        """, rows)
        
        conn.commit()
        cur.close()
        conn.close()
        return True
    
    except Exception as e:
        print(f"âŒ DBä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False

# =========================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================
def main():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("="*80)
    print("ğŸ‡ ç«¶é¦¬ãƒ¬ãƒ¼ã‚¹çµæœã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹")
    print("="*80)
    
    # å–å¾—æ¸ˆã¿IDã‚’ãƒ­ãƒ¼ãƒ‰
    done_ids = load_done_ids()
    
    # å–å¾—æœŸé–“ã‚’æ±ºå®š
    start_year, end_year = get_date_range()
    print(f"ğŸ“… å–å¾—æœŸé–“: {start_year}å¹´ ã€œ {end_year}å¹´")
    
    # ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰
    course_codes = [
        "01",  # æœ­å¹Œ
        "02",  # å‡½é¤¨
        "03",  # ç¦å³¶
        "04",  # æ–°æ½Ÿ
        "05",  # æ±äº¬
        "06",  # ä¸­å±±
        "07",  # ä¸­äº¬
        "08",  # äº¬éƒ½
        "09",  # é˜ªç¥
        "10",  # å°å€‰
    ]
    
    total_scraped = 0
    total_skipped = 0
    total_new = 0
    
    # å¹´ã”ã¨ã«å‡¦ç†
    for year in range(start_year, end_year + 1):
        print(f"\nğŸ“† {year}å¹´ã®ãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—ä¸­...")
        
        # ç«¶é¦¬å ´ã”ã¨ã«å‡¦ç†
        for course_code in course_codes:
            # é–‹å‚¬å› (1-6)
            for kai in range(1, 7):
                # æ—¥æ•° (1-12)
                for day in range(1, 13):
                    
                    # ã“ã®æ—¥ã®ãƒ¬ãƒ¼ã‚¹ã‚’å‡¦ç†
                    day_has_race = False # ã“ã®æ—¥ã«ãƒ¬ãƒ¼ã‚¹ãŒã‚ã£ãŸã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
                    
                    # ãƒ¬ãƒ¼ã‚¹ç•ªå· (1-12)
                    for r in range(1, 13):
                        race_id = f"{year}{course_code}{kai:02}{day:02}{r:02}"
                        
                        # ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š
                        if race_id in done_ids:
                            total_skipped += 1
                            day_has_race = True # ã™ã§ã«DBã«ã‚ã‚‹ï¼ãƒ¬ãƒ¼ã‚¹ã¯å­˜åœ¨ã™ã‚‹
                            continue
                        
                        # ãƒ¬ãƒ¼ã‚¹çµæœã‚’å–å¾—
                        rows = scrape_race(race_id)
                        
                        # ãƒ¬ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ãªã„å ´åˆ
                        if rows is None:
                            # ã‚‚ã—ç¬¬1ãƒ¬ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ã€ãã®æ—¥ã¯é–‹å‚¬ãŒãªã„ã¨åˆ¤æ–­ã—ã¦ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                            # (ã“ã‚Œã«ã‚ˆã‚Šç„¡é§„ãªã‚¢ã‚¯ã‚»ã‚¹ã‚’æ¸›ã‚‰ã—ã¤ã¤ã€æ¬¡ã®æ—¥/æ¬¡ã®é–‹å‚¬ã¯ãƒã‚§ãƒƒã‚¯ã‚’ç¶šã‘ã‚‹)
                            if r == 1:
                                break
                            
                            # 1Rã¯ã‚ã‚‹ã®ã«é€”ä¸­ã®ãƒ¬ãƒ¼ã‚¹ãŒãªã„å ´åˆã¯ã€å˜ã«ãã®ãƒ¬ãƒ¼ã‚¹ãŒãªã„ã ã‘ã¨ã—ã¦æ¬¡ã¸
                            # (é€šå¸¸JRAã§ã¯ç¨€ã ãŒã€å¿µã®ãŸã‚ç¶šè¡Œ)
                            continue
                        
                        # ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã£ãŸ
                        day_has_race = True
                        
                        # DBä¿å­˜
                        if save_to_db(rows):
                            done_ids.add(race_id)
                            total_new += 1
                            print(f"âœ“ {race_id}: {len(rows)}é ­ã®çµæœã‚’ä¿å­˜")
                        else:
                            print(f"âŒ {race_id}: ä¿å­˜å¤±æ•—")
                        
                        total_scraped += 1
                        
                        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                        time.sleep(1)
                        
                        # é€²æ—è¡¨ç¤ºï¼ˆ100ãƒ¬ãƒ¼ã‚¹ã”ã¨ï¼‰
                        if total_scraped % 100 == 0:
                            print(f"   é€²æ—: {total_scraped}ãƒ¬ãƒ¼ã‚¹å–å¾—æ¸ˆã¿")
                    
                    # ç¬¬1ãƒ¬ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ãªã‹ã£ãŸå ´åˆã€ã¾ãŸã¯DBã«ã‚‚ãªã‹ã£ãŸå ´åˆã¯
                    # ã“ã®æ—¥ã¯é–‹å‚¬ãŒãªã„ã®ã§ã€ã‚¦ã‚§ã‚¤ãƒˆã‚’çŸ­ãã—ã¦æ¬¡ã®æ—¥ã¸
                    if not day_has_race:
                        # å­˜åœ¨ã—ãªã„æ—¥ã®ç¢ºèªã‚¢ã‚¯ã‚»ã‚¹è² è·è»½æ¸›ã®ãŸã‚ã®çŸ­ã„ã‚¹ãƒªãƒ¼ãƒ—
                        time.sleep(0.1)

    # æœ€çµ‚çµæœ
    print("\n" + "="*80)
    print("âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†")
    print("="*80)
    print(f"ğŸ“Š çµ±è¨ˆ:")
    print(f"   æ–°è¦å–å¾—: {total_new}ãƒ¬ãƒ¼ã‚¹")
    print(f"   ã‚¹ã‚­ãƒƒãƒ—: {total_skipped}ãƒ¬ãƒ¼ã‚¹")
    print(f"   åˆè¨ˆå–å¾—æ¸ˆã¿: {len(done_ids)}ãƒ¬ãƒ¼ã‚¹")
    print("="*80)

# =========================
# å®Ÿè¡Œ
# =========================
if __name__ == "__main__":
    main()
