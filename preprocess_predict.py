"""
äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å­¦ç¿’æ™‚ã¨åŒã˜ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´è¿‘3èµ°ã®ç‰¹å¾´é‡ã‚‚è¿½åŠ ã€‚
"""

import pandas as pd
import numpy as np
import joblib
from pathlib import Path

# å­¦ç¿’æ™‚ã¨åŒã˜ç‰¹å¾´é‡ç”Ÿæˆé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from feature_engineering import apply_all_features
from add_passing_features import add_passing_features
from add_jockey_style_features import add_jockey_style_features
from add_speed_features import add_speed_features
from add_distance_preference_features import add_distance_preference_features
from add_recent_diff_features import add_recent_diff_features

# éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ç®¡ç†
try:
    from horse_history_db import HorseHistoryDB, calculate_recent_features
    HISTORY_AVAILABLE = True
except ImportError:
    HISTORY_AVAILABLE = False
    print("âš ï¸  horse_history_db.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚éå»ãƒ¬ãƒ¼ã‚¹æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")

# ç‰¹å¾´é‡ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
try:
    from feature_metadata import FeatureMetadata
    METADATA_AVAILABLE = True
except ImportError:
    METADATA_AVAILABLE = False
    print("âš ï¸  feature_metadata.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")


def preprocess_for_prediction(df_race, feature_list_path="feature_list.pkl",
                              use_history=True, history_csv="data/race_history.csv",
                              metadata_path="feature_metadata.json"):
    """
    äºˆæ¸¬ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†
    
    å­¦ç¿’æ™‚ã¨åŒã˜ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã€å­¦ç¿’æ™‚ã®ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã«åˆã‚ã›ã‚‹ã€‚
    
    Args:
        df_race: ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆå‡ºèµ°è¡¨ï¼‰
        feature_list_path: å­¦ç¿’æ™‚ã®ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
        use_history: éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        history_csv: éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®CSVãƒ•ã‚¡ã‚¤ãƒ«
        metadata_path: ç‰¹å¾´é‡ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«
    
    Returns:
        X: äºˆæ¸¬ç”¨ã®ç‰¹å¾´é‡DataFrame
    """
    
    # ========================================
    # 0. ç‰¹å¾´é‡ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    # ========================================
    metadata = None
    if METADATA_AVAILABLE and Path(metadata_path).exists():
        try:
            metadata = FeatureMetadata.load(metadata_path)
            print("   âœ“ ç‰¹å¾´é‡ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‰å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
            n_recent = metadata.preprocessing_params.get('n_recent', 3)
            print(f"   âœ“ ç›´è¿‘{n_recent}èµ°ã‚’ä½¿ç”¨")
        except Exception as e:
            print(f"   âš ï¸  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            n_recent = 3
    else:
        print("   â„¹ï¸  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰")
        n_recent = 3
    
    # ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼
    df = df_race.copy()
    
    # ========================================
    # 1. éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨çµ±åˆ
    # ========================================
    if use_history and HISTORY_AVAILABLE:
        print("   ğŸ“š éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        try:
            history_db = HorseHistoryDB(history_csv=history_csv)
            df = calculate_recent_features(df, history_db, n_races=3)
            print("   âœ“ éå»ãƒ¬ãƒ¼ã‚¹ç‰¹å¾´é‡ã‚’è¿½åŠ ")
        except Exception as e:
            print(f"   âš ï¸  éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—: {e}")
            print("   â†’ éå»ãƒ¬ãƒ¼ã‚¹ç‰¹å¾´é‡ãªã—ã§ç¶šè¡Œ")
    elif use_history and not HISTORY_AVAILABLE:
        print("   âš ï¸  horse_history_db.py ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    # ========================================
    # 2. åŸºæœ¬çš„ãªå‰å‡¦ç†
    # ========================================
    print("   ğŸ”§ åŸºæœ¬ç‰¹å¾´é‡ã‚’ç”Ÿæˆä¸­...")
    
    # feature_engineering.pyã®å‡¦ç†ã‚’é©ç”¨
    df = apply_all_features(df)
    
    # ========================================
    # 2. horse_id ã®ç”Ÿæˆ
    # ========================================
    if "horse_id" not in df.columns and "horse_name" in df.columns:
        df["horse_id"] = pd.factorize(df["horse_name"])[0]
    
    # ========================================
    # 3. é«˜åº¦ãªç‰¹å¾´é‡ç”Ÿæˆ
    # ========================================
    
    # 3-1. é€šéé †ç‰¹å¾´é‡
    # æ³¨æ„: äºˆæ¸¬æ™‚ã«ã¯éå»ãƒ¬ãƒ¼ã‚¹ã®é€šéé †ãŒãªã„ãŸã‚ã€
    # ã“ã®ç‰¹å¾´é‡ã¯éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
    # ã“ã“ã§ã¯ãƒ€ãƒŸãƒ¼ã¨ã—ã¦å‡¦ç†ï¼ˆå®Ÿè£…æ™‚ã¯éå»ãƒ¬ãƒ¼ã‚¹DBå‚ç…§ï¼‰
    print("   âœ“ é€šéé †ç‰¹å¾´é‡...")
    if "passing" in df.columns:
        df = add_passing_features(df)
    else:
        # é€šéé †ãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        df["passing_1c"] = np.nan
        df["passing_4c"] = np.nan
        df["passing_gain"] = np.nan
        df["style_front"] = 0
        df["style_stalker"] = 0
        df["style_closer"] = 0
    
    # 3-2. ã‚¹ãƒ”ãƒ¼ãƒ‰ç‰¹å¾´é‡
    print("   âœ“ ã‚¹ãƒ”ãƒ¼ãƒ‰ç‰¹å¾´é‡...")
    # äºˆæ¸¬æ™‚ã«ã¯time_secãŒãªã„ãŸã‚ã€éå»ãƒ¬ãƒ¼ã‚¹ã®å¹³å‡å€¤ã‚’ä½¿ç”¨
    if "distance" in df.columns:
        # æš«å®š: æ¨™æº–çš„ãªã‚¹ãƒ”ãƒ¼ãƒ‰å€¤ã‚’è¨­å®š
        if "time_sec" not in df.columns or df["time_sec"].isna().all():
            # è·é›¢ã‹ã‚‰æ¨å®šã‚¿ã‚¤ãƒ ï¼ˆèŠã®å ´åˆï¼‰
            df["time_sec"] = df["distance"] / 15.0  # ç´„15m/s
        
        df = add_speed_features(df)
    else:
        df["speed"] = np.nan
        df["speed_recent_avg_3"] = np.nan
        df["speed_recent_diff_3"] = np.nan
    
    # 3-3. è·é›¢é©æ€§ç‰¹å¾´é‡
    print("   âœ“ è·é›¢é©æ€§ç‰¹å¾´é‡...")
    if "distance" in df.columns and "speed" in df.columns:
        df = add_distance_preference_features(df)
    else:
        df["distance_band"] = 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯mileï¼ˆæ•°å€¤ï¼‰
        df["speed_dist_avg"] = np.nan
        df["speed_dist_diff"] = np.nan
        df["is_favorite_distance"] = 0
    
    # 3-4. é¨æ‰‹ç‰¹å¾´é‡
    print("   âœ“ é¨æ‰‹ç‰¹å¾´é‡...")
    if "jockey" in df.columns:
        df = add_jockey_style_features(df, "jockey_profile.csv")
    
    # 3-5. è¿‘èµ°å·®åˆ†ç‰¹å¾´é‡
    print("   âœ“ è¿‘èµ°å·®åˆ†ç‰¹å¾´é‡...")
    # æ³¨æ„: åŒä¸€ãƒ¬ãƒ¼ã‚¹å†…ã®ãƒ‡ãƒ¼ã‚¿ã—ã‹ãªã„ãŸã‚ã€è¿‘èµ°å·®åˆ†ã¯è¨ˆç®—ã§ããªã„
    # æœ¬æ¥ã¯éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã¦è¨ˆç®—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
    # ã“ã“ã§ã¯æ¬ æå€¤ã¨ã—ã¦å‡¦ç†
    df = add_recent_diff_features(df, n_recent=3)
    
    # ========================================
    # 4. å­¦ç¿’æ™‚ã®ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã«åˆã‚ã›ã‚‹
    # ========================================
    print(f"   ğŸ“‹ å­¦ç¿’æ™‚ã®ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿: {feature_list_path}")
    
    if not Path(feature_list_path).exists():
        raise FileNotFoundError(
            f"ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {feature_list_path}\n"
            f"å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆtrain_lgbm_ranker_improved.pyï¼‰ã‚’å®Ÿè¡Œã—ã¦ã€"
            f"feature_list.pkl ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        )
    
    # å­¦ç¿’æ™‚ã®ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
    feature_list = joblib.load(feature_list_path)
    
    print(f"   âœ“ å­¦ç¿’æ™‚ã®ç‰¹å¾´é‡æ•°: {len(feature_list)}")
    print(f"   âœ“ ç¾åœ¨ã®ç‰¹å¾´é‡æ•°: {len([c for c in df.columns if c in feature_list])}")
    
    # ä¸è¶³ã—ã¦ã„ã‚‹ç‰¹å¾´é‡ã‚’0ã§åŸ‹ã‚ã‚‹
    missing_features = set(feature_list) - set(df.columns)
    if missing_features:
        print(f"   âš ï¸  ä¸è¶³ã—ã¦ã„ã‚‹ç‰¹å¾´é‡: {len(missing_features)}å€‹")
        for feat in missing_features:
            df[feat] = 0
    
    # å­¦ç¿’æ™‚ã®ç‰¹å¾´é‡ã®ã¿ã‚’æŠ½å‡ºï¼ˆé †åºã‚‚ä¿æŒï¼‰
    X = df[feature_list]
    
    # ========================================
    # 5. ãƒ‡ãƒ¼ã‚¿å‹ã®æœ€çµ‚æ¤œè¨¼ã¨ä¿®æ­£
    # ========================================
    print(f"   ğŸ” ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ¤œè¨¼ä¸­...")
    
    # objectå‹ã®ã‚«ãƒ©ãƒ ã‚’ãƒã‚§ãƒƒã‚¯
    object_cols = X.select_dtypes(include=['object']).columns.tolist()
    if object_cols:
        print(f"   âš ï¸  objectå‹ã‚«ãƒ©ãƒ ã‚’æ¤œå‡º: {object_cols}")
        for col in object_cols:
            # æ•°å€¤å¤‰æ›ã‚’è©¦ã¿ã‚‹
            try:
                X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)
                print(f"      âœ“ {col} ã‚’æ•°å€¤åŒ–")
            except:
                # Label Encoding
                X[col] = pd.factorize(X[col])[0]
                print(f"      âœ“ {col} ã‚’Label Encoding")
    
    # NaN/Infãƒã‚§ãƒƒã‚¯
    if X.isna().any().any():
        print(f"   âš ï¸  NaNã‚’æ¤œå‡º - 0ã§åŸ‹ã‚ã¾ã™")
        X = X.fillna(0)
    
    if np.isinf(X.select_dtypes(include=[np.number])).any().any():
        print(f"   âš ï¸  ç„¡é™å¤§ã‚’æ¤œå‡º - 0ã§ç½®æ›")
        X = X.replace([np.inf, -np.inf], 0)
    
    print(f"   âœ… æœ€çµ‚ç‰¹å¾´é‡æ•°: {len(X.columns)}")
    print(f"   âœ… ãƒ‡ãƒ¼ã‚¿å‹: {X.dtypes.unique()}")
    
    return X


def load_past_race_data(horse_name, n_races=5):
    """
    éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå°†æ¥ã®å®Ÿè£…ç”¨ï¼‰
    
    Args:
        horse_name: é¦¬å
        n_races: å–å¾—ã™ã‚‹éå»ãƒ¬ãƒ¼ã‚¹æ•°
    
    Returns:
        éå»ãƒ¬ãƒ¼ã‚¹ã®DataFrame
    """
    # TODO: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    # ç¾åœ¨ã¯ãƒ€ãƒŸãƒ¼å®Ÿè£…
    return pd.DataFrame()


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    print("äºˆæ¸¬ç”¨å‰å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆ")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    sample_data = {
        "horse_no": [1, 2, 3],
        "horse_name": ["ãƒ†ã‚¹ãƒˆãƒ›ãƒ¼ã‚¹1", "ãƒ†ã‚¹ãƒˆãƒ›ãƒ¼ã‚¹2", "ãƒ†ã‚¹ãƒˆãƒ›ãƒ¼ã‚¹3"],
        "jockey": ["æ­¦è±Š", "å²©ç”°åº·èª ", "å·ç”°å°†é›…"],
        "age_sex": ["4ç‰¡", "5ç‰¡", "3ç‰"],
        "weight_carrier": [58, 57, 54],
        "horse_weight": ["480(+2)", "470(-3)", "450(+5)"],
        "distance": [1800, 1800, 1800],
    }
    
    df = pd.DataFrame(sample_data)
    
    try:
        X = preprocess_for_prediction(df)
        print(f"\nâœ… æˆåŠŸï¼ç‰¹å¾´é‡å½¢çŠ¶: {X.shape}")
        print(f"ç‰¹å¾´é‡: {X.columns.tolist()[:10]}...")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
