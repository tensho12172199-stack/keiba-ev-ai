"""
Supabaseéå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦é¦¬ã®éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional
from datetime import datetime
import os
from supabase import create_client, Client


class SupabaseHorseHistoryDB:
    """
    Supabaseï¼ˆPostgreSQLï¼‰ã‚’ä½¿ç”¨ã—ãŸéå»ãƒ¬ãƒ¼ã‚¹ç®¡ç†
    
    ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ :
        race_results:
            - race_id (text)
            - race_date (date)
            - race_name (text)
            - horse_name (text)
            - rank (integer)
            - time (text)
            - time_sec (float)
            - distance (integer)
            - passing (text)
            - speed (float)
            - jockey (text)
            - weight_carrier (float)
            - horse_weight (text)
            - odds (float)
            - popularity (integer)
            - ãã®ä»–...
    """
    
    def __init__(self, url: Optional[str] = None, key: Optional[str] = None):
        """
        Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        
        Args:
            url: Supabase URLï¼ˆç’°å¢ƒå¤‰æ•° SUPABASE_URL ã‹ã‚‰å–å¾—ã‚‚å¯ï¼‰
            key: Supabase API Keyï¼ˆç’°å¢ƒå¤‰æ•° SUPABASE_KEY ã‹ã‚‰å–å¾—ã‚‚å¯ï¼‰
        """
        self.url = url or os.getenv("SUPABASE_URL")
        self.key = key or os.getenv("SUPABASE_KEY")
        
        if not self.url or not self.key:
            raise ValueError(
                "Supabase URLã¨KeyãŒå¿…è¦ã§ã™ã€‚\n"
                "ç’°å¢ƒå¤‰æ•° SUPABASE_URL ã¨ SUPABASE_KEY ã‚’è¨­å®šã™ã‚‹ã‹ã€\n"
                "å¼•æ•°ã§ç›´æ¥æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            )
        
        try:
            self.client: Client = create_client(self.url, self.key)
            print("âœ… Supabaseã«æ¥ç¶šã—ã¾ã—ãŸ")
        except Exception as e:
            raise ConnectionError(f"Supabaseã¸ã®æ¥ç¶šã«å¤±æ•—: {e}")
    
    def create_table(self):
        """
        race_resultsãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼ˆåˆå›ã®ã¿ï¼‰
        
        Note: Supabase Web UIã¾ãŸã¯SQLã‚¨ãƒ‡ã‚£ã‚¿ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œ:
        
        è©³ç´°ã¯ supabase_schema.sql ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
        
        ä¸»è¦ã‚«ãƒ©ãƒ :
        - race_id (TEXT): ãƒ¬ãƒ¼ã‚¹ID
        - race_date (DATE): ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜
        - horse_name (TEXT): é¦¬å
        - horse_no (INTEGER): é¦¬ç•ª
        - rank (INTEGER): ç€é †
        - distance (INTEGER): è·é›¢
        - course_type (TEXT): èŠ/ãƒ€ãƒ¼ãƒˆ
        - track_direction (TEXT): å³/å·¦
        - weather (TEXT): å¤©å€™
        - track_condition (TEXT): é¦¬å ´çŠ¶æ…‹
        - speed (FLOAT): ã‚¹ãƒ”ãƒ¼ãƒ‰
        - jockey (TEXT): é¨æ‰‹
        - passing_4c (FLOAT): 4ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †
        - ãã®ä»–å¤šæ•°...
        """
        print("âš ï¸  ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã¯Supabase Web UIã§å®Ÿè¡Œã—ã¦ãã ã•ã„")
        print("    è©³ç´°: supabase_schema.sql ã‚’å‚ç…§")
    
    def upload_csv_to_supabase(self, csv_path: str, batch_size: int = 1000):
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Supabaseã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        
        Args:
            csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            batch_size: ä¸€åº¦ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹è¡Œæ•°
        """
        print(f"\nğŸ“¤ Supabaseã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­: {csv_path}")
        
        # CSVã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(csv_path)
        print(f"   âœ“ {len(df):,}è¡Œã‚’èª­ã¿è¾¼ã¿")
        
        # æ—¥ä»˜å‹ã«å¤‰æ›
        if 'race_date' in df.columns:
            df['race_date'] = pd.to_datetime(df['race_date'], errors='coerce')
            df['race_date'] = df['race_date'].dt.strftime('%Y-%m-%d')
        
        # NaNã‚’Noneã«å¤‰æ›ï¼ˆJSONäº’æ›ï¼‰
        df = df.where(pd.notna(df), None)
        
        # ãƒãƒƒãƒã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        total_uploaded = 0
        total_batches = (len(df) + batch_size - 1) // batch_size
        
        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i + batch_size]
            records = batch.to_dict('records')
            
            try:
                self.client.table('race_results').insert(records).execute()
                total_uploaded += len(records)
                print(f"   âœ“ ãƒãƒƒãƒ {i // batch_size + 1}/{total_batches}: {total_uploaded:,}è¡Œã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            except Exception as e:
                print(f"   âŒ ãƒãƒƒãƒ {i // batch_size + 1} ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        print(f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {total_uploaded:,}è¡Œ")
    
    def upload_directory_to_supabase(self, data_dir: str = "data", batch_size: int = 1000):
        """
        ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’Supabaseã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        
        Args:
            data_dir: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
        """
        from pathlib import Path
        
        print(f"\nğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {data_dir}")
        
        csv_files = list(Path(data_dir).glob("*.csv"))
        
        if not csv_files:
            print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
            return
        
        print(f"   è¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(csv_files)}å€‹")
        
        for csv_file in csv_files:
            self.upload_csv_to_supabase(str(csv_file), batch_size)
    
    def get_horse_recent_races(
        self,
        horse_name: str,
        before_date: Optional[str] = None,
        n_races: int = 3
    ) -> pd.DataFrame:
        """
        é¦¬ã®ç›´è¿‘Nèµ°ã‚’å–å¾—ï¼ˆSupabaseã‹ã‚‰ï¼‰
        
        Args:
            horse_name: é¦¬å
            before_date: ã“ã®æ—¥ä»˜ã‚ˆã‚Šå‰ã®ãƒ¬ãƒ¼ã‚¹ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
            n_races: å–å¾—ã™ã‚‹éå»ãƒ¬ãƒ¼ã‚¹æ•°
        
        Returns:
            éå»ãƒ¬ãƒ¼ã‚¹ã®DataFrame
        """
        try:
            # ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
            query = self.client.table('race_results') \
                .select('*') \
                .eq('horse_name', horse_name) \
                .order('race_date', desc=True)
            
            # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
            if before_date:
                query = query.lt('race_date', before_date)
            
            # å®Ÿè¡Œ
            response = query.limit(n_races).execute()
            
            # DataFrameã«å¤‰æ›
            if response.data:
                return pd.DataFrame(response.data)
            else:
                return pd.DataFrame()
        
        except Exception as e:
            print(f"   âš ï¸  {horse_name}ã®éå»ãƒ¬ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def get_batch_recent_races(
        self,
        horse_names: List[str],
        before_date: Optional[str] = None,
        n_races: int = 3
    ) -> Dict[str, pd.DataFrame]:
        """
        è¤‡æ•°ã®é¦¬ã®ç›´è¿‘Nèµ°ã‚’ä¸€æ‹¬å–å¾—
        
        Args:
            horse_names: é¦¬åã®ãƒªã‚¹ãƒˆ
            before_date: ã“ã®æ—¥ä»˜ã‚ˆã‚Šå‰ã®ãƒ¬ãƒ¼ã‚¹
            n_races: å–å¾—ã™ã‚‹éå»ãƒ¬ãƒ¼ã‚¹æ•°
        
        Returns:
            {horse_name: DataFrame} ã®è¾æ›¸
        """
        results = {}
        
        print(f"   ğŸ“Š {len(horse_names)}é ­ã®éå»ãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—ä¸­...")
        
        for horse_name in horse_names:
            results[horse_name] = self.get_horse_recent_races(
                horse_name, before_date, n_races
            )
        
        # çµ±è¨ˆ
        found_count = sum(1 for df in results.values() if not df.empty)
        print(f"   âœ“ éå»ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã£ãŸé¦¬: {found_count}é ­")
        
        return results
    
    def search_races(
        self,
        race_date_from: Optional[str] = None,
        race_date_to: Optional[str] = None,
        jockey: Optional[str] = None,
        limit: int = 100
    ) -> pd.DataFrame:
        """
        ãƒ¬ãƒ¼ã‚¹ã‚’æ¤œç´¢
        
        Args:
            race_date_from: é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰
            race_date_to: çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰
            jockey: é¨æ‰‹å
            limit: æœ€å¤§å–å¾—ä»¶æ•°
        
        Returns:
            æ¤œç´¢çµæœã®DataFrame
        """
        query = self.client.table('race_results').select('*')
        
        if race_date_from:
            query = query.gte('race_date', race_date_from)
        if race_date_to:
            query = query.lte('race_date', race_date_to)
        if jockey:
            query = query.eq('jockey', jockey)
        
        response = query.limit(limit).execute()
        
        if response.data:
            return pd.DataFrame(response.data)
        else:
            return pd.DataFrame()
    
    def get_stats(self) -> Dict:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
        """
        try:
            # ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
            count_response = self.client.table('race_results') \
                .select('*', count='exact') \
                .execute()
            total_records = count_response.count
            
            # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªé¦¬ã®æ•°ï¼ˆRPCé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
            # Note: ä»¥ä¸‹ã®SQLé–¢æ•°ã‚’äº‹å‰ã«Supabaseã§ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
            # CREATE OR REPLACE FUNCTION get_unique_horses_count()
            # RETURNS bigint AS $$
            #   SELECT COUNT(DISTINCT horse_name) FROM race_results;
            # $$ LANGUAGE sql;
            
            stats = {
                'total_records': total_records,
                'status': 'connected'
            }
            
            return stats
            
        except Exception as e:
            print(f"çµ±è¨ˆæƒ…å ±ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'total_records': 0, 'status': 'error'}
    
    def delete_all_data(self):
        """
        å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆæ³¨æ„ï¼ï¼‰
        
        Warning: ã“ã®æ“ä½œã¯å–ã‚Šæ¶ˆã›ã¾ã›ã‚“
        """
        print("âš ï¸  å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™ã€‚æœ¬å½“ã«ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ")
        confirm = input("å‰Šé™¤ã™ã‚‹å ´åˆã¯ 'DELETE' ã¨å…¥åŠ›: ")
        
        if confirm == "DELETE":
            try:
                # å…¨å‰Šé™¤ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯æ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰
                self.client.table('race_results').delete().neq('id', 0).execute()
                print("âœ… å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            except Exception as e:
                print(f"âŒ å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")


def calculate_recent_features_supabase(
    current_race_df: pd.DataFrame,
    supabase_db: SupabaseHorseHistoryDB,
    n_races: int = 3
) -> pd.DataFrame:
    """
    Supabaseã‹ã‚‰ç›´è¿‘Nèµ°ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ç‰¹å¾´é‡ã‚’è¨ˆç®—
    
    Args:
        current_race_df: ç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
        supabase_db: SupabaseHorseHistoryDB ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        n_races: å‚ç…§ã™ã‚‹éå»ãƒ¬ãƒ¼ã‚¹æ•°
    
    Returns:
        ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ãŸDataFrame
    """
    df = current_race_df.copy()
    
    # ãƒ¬ãƒ¼ã‚¹ã®æ—¥ä»˜ã‚’å–å¾—
    race_date = None
    if 'race_date' in df.columns and not df['race_date'].isna().all():
        race_date = pd.to_datetime(df['race_date'].iloc[0]).strftime('%Y-%m-%d')
    
    print(f"\nğŸ” Supabaseã‹ã‚‰ç›´è¿‘{n_races}èµ°ã‚’å–å¾—ä¸­...")
    
    # å„é¦¬ã®éå»ãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—
    horse_names = df['horse_name'].unique().tolist()
    past_races_dict = supabase_db.get_batch_recent_races(
        horse_names, before_date=race_date, n_races=n_races
    )
    
    # ç‰¹å¾´é‡ã‚’è¨ˆç®—
    features_list = []
    
    for idx, row in df.iterrows():
        horse_name = row['horse_name']
        past_races = past_races_dict.get(horse_name, pd.DataFrame())
        
        features = {
            'horse_name': horse_name,
            'past_races_count': len(past_races),
        }
        
        if not past_races.empty:
            # å¹³å‡ç€é †
            if 'rank' in past_races.columns:
                features['recent_avg_rank'] = past_races['rank'].mean()
                features['recent_best_rank'] = past_races['rank'].min()
            
            # å¹³å‡ã‚¿ã‚¤ãƒ 
            if 'time_sec' in past_races.columns:
                features['recent_avg_time_sec'] = past_races['time_sec'].mean()
            
            # å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰
            if 'speed' in past_races.columns:
                features['recent_avg_speed'] = past_races['speed'].mean()
            
            # å‹ç‡
            if 'rank' in past_races.columns:
                features['recent_win_rate'] = (past_races['rank'] == 1).mean()
                features['recent_top3_rate'] = (past_races['rank'] <= 3).mean()
            
            # é€£ç¶šå‡ºèµ°æ—¥æ•°
            if 'race_date' in past_races.columns and race_date:
                last_race_date = pd.to_datetime(past_races['race_date'].iloc[0])
                current_date = pd.to_datetime(race_date)
                days_since_last = (current_date - last_race_date).days
                features['days_since_last_race'] = days_since_last
            
            # è„šè³ª
            if 'passing_4c' in past_races.columns:
                features['recent_avg_pos_4c'] = past_races['passing_4c'].mean()
        
        features_list.append(features)
    
    # DataFrameã«å¤‰æ›
    features_df = pd.DataFrame(features_list)
    
    # ãƒãƒ¼ã‚¸
    df = df.merge(features_df, on='horse_name', how='left')
    
    # æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹
    for col in features_df.columns:
        if col != 'horse_name' and col in df.columns:
            df[col] = df[col].fillna(0)
    
    print(f"   âœ“ è¿½åŠ ã•ã‚ŒãŸç‰¹å¾´é‡: {len(features_df.columns) - 1}å€‹")
    
    return df


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆãƒ»ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    print("="*80)
    print("ğŸ‡ Supabaseéå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ")
    print("="*80)
    
    # ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_KEY")
    
    if not url or not key:
        print("\nâš ï¸  ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
        print("   export SUPABASE_URL='your-project-url'")
        print("   export SUPABASE_KEY='your-anon-key'")
        print("\n   ã¾ãŸã¯ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜è¼‰:")
        print("   SUPABASE_URL=your-project-url")
        print("   SUPABASE_KEY=your-anon-key")
    else:
        try:
            # Supabaseã«æ¥ç¶š
            db = SupabaseHorseHistoryDB()
            
            # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
            stats = db.get_stats()
            print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ:")
            print(f"   ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {stats.get('total_records', 0):,}")
            print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {stats.get('status', 'unknown')}")
            
            print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
            print("   # CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            print("   db.upload_csv_to_supabase('data/race_2019.csv')")
            print("")
            print("   # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            print("   db.upload_directory_to_supabase('data')")
            print("")
            print("   # é¦¬ã®éå»ãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—")
            print("   past = db.get_horse_recent_races('ãƒ‰ã‚¦ãƒ‡ãƒ¥ãƒ¼ã‚¹', n_races=3)")
            
        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
