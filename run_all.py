"""
ç«¶é¦¬äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« ã‚ªãƒ¼ãƒ«ã‚¤ãƒ³ãƒ¯ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‹ã‚‰å­¦ç¿’ã¾ã§ä¸€æ°—ã«å®Ÿè¡Œã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python run_all.py horse_race_data_2019.csv
    python run_all.py data/race_*.csv
"""

import sys
import pandas as pd
from pathlib import Path
import shutil
import glob

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from preprocess_race_data import preprocess_race_data


def setup_environment():
    """ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    print("\n" + "="*80)
    print("ğŸš€ ç«¶é¦¬äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« ã‚ªãƒ¼ãƒ«ã‚¤ãƒ³ãƒ¯ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("="*80)
    
    # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    dirs = ["data", "outputs"]
    for d in dirs:
        Path(d).mkdir(exist_ok=True)
    
    print("\nâœ“ ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")


def preprocess_files(input_files):
    """
    è¤‡æ•°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰å‡¦ç†
    
    Args:
        input_files: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
    """
    print("\n" + "="*80)
    print("ğŸ“Š STEP 1: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†")
    print("="*80)
    
    processed_files = []
    
    for i, input_file in enumerate(input_files, 1):
        print(f"\n[{i}/{len(input_files)}] å‡¦ç†ä¸­: {Path(input_file).name}")
        print("-" * 80)
        
        try:
            # å‡ºåŠ›å…ˆã‚’dataãƒ•ã‚©ãƒ«ãƒ€ã«
            input_path = Path(input_file)
            output_file = Path("data") / f"{input_path.stem}_processed.csv"
            
            # å‰å‡¦ç†å®Ÿè¡Œ
            df = preprocess_race_data(input_file, str(output_file))
            processed_files.append(str(output_file))
            
            print(f"âœ“ ä¿å­˜: {output_file}")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    print("\n" + "="*80)
    print(f"âœ… å‰å‡¦ç†å®Œäº†: {len(processed_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
    print("="*80)
    
    return processed_files


def check_processed_data():
    """å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª"""
    print("\n" + "="*80)
    print("ğŸ” å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª")
    print("="*80)
    
    data_files = list(Path("data").glob("*_processed.csv"))
    
    if not data_files:
        print("âŒ dataãƒ•ã‚©ãƒ«ãƒ€ã«å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return False
    
    print(f"\nå‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«: {len(data_files)}å€‹")
    
    total_rows = 0
    total_races = 0
    
    for f in data_files:
        df = pd.read_csv(f)
        rows = len(df)
        races = df['race_id'].nunique() if 'race_id' in df.columns else 0
        total_rows += rows
        total_races += races
        
        print(f"  âœ“ {f.name:40s} {rows:>8,}è¡Œ / {races:>6,}ãƒ¬ãƒ¼ã‚¹")
    
    print(f"\nåˆè¨ˆ: {total_rows:,}è¡Œ / {total_races:,}ãƒ¬ãƒ¼ã‚¹")
    
    # å¿…é ˆã‚«ãƒ©ãƒ ã®ãƒã‚§ãƒƒã‚¯
    print("\nå¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª:")
    df_sample = pd.read_csv(data_files[0])
    required_cols = ["race_id", "horse_name", "rank"]
    recommended_cols = ["race_date", "distance", "time", "passing", "jockey"]
    
    for col in required_cols:
        status = "âœ“" if col in df_sample.columns else "âŒ"
        print(f"  {status} {col}")
    
    print("\næ¨å¥¨ã‚«ãƒ©ãƒ :")
    for col in recommended_cols:
        status = "âœ“" if col in df_sample.columns else "âš ï¸"
        print(f"  {status} {col}")
    
    return True


def run_training():
    """å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ"""
    print("\n" + "="*80)
    print("ğŸ“ STEP 2: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    print("="*80)
    
    try:
        # train_lgbm_ranker_improved.py ã®main()ã‚’ç›´æ¥å®Ÿè¡Œ
        from train_lgbm_ranker_improved import main as train_main
        
        print("\nå­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
        train_main()
        
        return True
        
    except Exception as e:
        print(f"\nâŒ å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return False


def display_results():
    """çµæœã®è¡¨ç¤º"""
    print("\n" + "="*80)
    print("ğŸ“Š å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼")
    print("="*80)
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    model_file = Path("outputs/horse_racing_lgbm_ranker.txt")
    if model_file.exists():
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {model_file}")
        print(f"   ã‚µã‚¤ã‚º: {model_file.stat().st_size / 1024:.1f} KB")
    else:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ç‰¹å¾´é‡é‡è¦åº¦ã®ç¢ºèª
    importance_file = Path("outputs/feature_importance.csv")
    if importance_file.exists():
        print(f"\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ (Top 10)")
        print("-" * 80)
        df_imp = pd.read_csv(importance_file)
        for idx, row in df_imp.head(10).iterrows():
            print(f"  {idx+1:2d}. {row['feature']:40s} {row['importance']:>10.1f}")
    
    # è©•ä¾¡æŒ‡æ¨™ã®ç¢ºèª
    metrics_file = Path("outputs/training_metrics.csv")
    if metrics_file.exists():
        df_metrics = pd.read_csv(metrics_file)
        hit_rate = (df_metrics['hit_top3'] > 0).mean()
        print(f"\nğŸ¯ äºˆæ¸¬ç²¾åº¦")
        print("-" * 80)
        print(f"  Top3çš„ä¸­ç‡: {hit_rate:.2%}")
        print(f"  å¹³å‡çš„ä¸­é ­æ•°: {df_metrics['hit_top3'].mean():.2f}")
    
    print("\n" + "="*80)
    print("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("="*80)
    
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. ç‰¹å¾´é‡é‡è¦åº¦ã‚’ç¢ºèª: outputs/feature_importance.csv")
    print("  2. äºˆæ¸¬ã‚’å®Ÿè¡Œ: python predict.py <æ–°ã—ã„ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿.csv>")


def main(input_patterns):
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    
    Args:
        input_patterns: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒªã‚¹ãƒˆ
    """
    try:
        # ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        setup_environment()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®å–å¾—
        input_files = []
        for pattern in input_patterns:
            if '*' in pattern or '?' in pattern:
                matched = glob.glob(pattern)
                input_files.extend(matched)
            else:
                if Path(pattern).exists():
                    input_files.append(pattern)
                else:
                    print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
        
        if not input_files:
            print("âŒ å‡¦ç†å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            print("\nä½¿ç”¨æ–¹æ³•:")
            print("  python run_all.py horse_race_data_2019.csv")
            print("  python run_all.py data/race_*.csv")
            return False
        
        # é‡è¤‡å‰Šé™¤
        input_files = list(set(input_files))
        input_files.sort()
        
        print(f"\nğŸ“‹ å‡¦ç†å¯¾è±¡: {len(input_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        for f in input_files:
            print(f"  - {f}")
        
        # STEP 1: å‰å‡¦ç†
        processed_files = preprocess_files(input_files)
        
        if not processed_files:
            print("âŒ å‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        if not check_processed_data():
            return False
        
        # STEP 2: å­¦ç¿’
        success = run_training()
        
        if not success:
            print("âŒ å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        # çµæœè¡¨ç¤º
        display_results()
        
        return True
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return False
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("=" * 80)
        print("ğŸ‡ ç«¶é¦¬äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« ã‚ªãƒ¼ãƒ«ã‚¤ãƒ³ãƒ¯ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
        print("=" * 80)
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python run_all.py <CSVãƒ•ã‚¡ã‚¤ãƒ«> [<CSVãƒ•ã‚¡ã‚¤ãƒ«2> ...]")
        print("\nä¾‹:")
        print("  python run_all.py horse_race_data_2019.csv")
        print("  python run_all.py data/race_2019.csv data/race_2020.csv")
        print("  python run_all.py data/race_*.csv")
        print("\nå‡¦ç†å†…å®¹:")
        print("  1. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆrace_detailsã‹ã‚‰è·é›¢ç­‰ã‚’æŠ½å‡ºï¼‰")
        print("  2. ç‰¹å¾´é‡ç”Ÿæˆ")
        print("  3. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
        print("  4. çµæœã®ä¿å­˜ã¨è¡¨ç¤º")
        print("\nå‡ºåŠ›:")
        print("  - data/*_processed.csv (å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿)")
        print("  - outputs/horse_racing_lgbm_ranker.txt (ãƒ¢ãƒ‡ãƒ«)")
        print("  - outputs/feature_importance.csv (ç‰¹å¾´é‡é‡è¦åº¦)")
        print("=" * 80)
        sys.exit(1)
    
    patterns = sys.argv[1:]
    success = main(patterns)
    
    sys.exit(0 if success else 1)
